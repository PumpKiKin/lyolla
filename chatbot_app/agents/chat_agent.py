from .base_agent import BaseAgent
from .vector_store_agent import VectorStoreAgent
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
from langchain.schema.output_parser import StrOutputParser


class ChatAgent(BaseAgent):
    """ëŒ€í™” ê´€ë¦¬ + LLM ì‘ë‹µ ë‹´ë‹¹"""

    def __init__(self):
        self.vector_agent = VectorStoreAgent()
        self.model = ChatGoogleGenerativeAI(model="gemini-2.5-flash")

    def run(self, user_question: str, history: list):
        # ğŸ” RAG ê²€ìƒ‰
        docs = self.vector_agent.run(user_question)

        # ğŸ“œ ìµœê·¼ ëŒ€í™” ì´ë ¥ í¬ë§·
        history_text = "\n".join(
            [f"{h['role']}: {h['content']}" for h in history[-8:]]
        )

        # ğŸ¯ í”„ë¡¬í”„íŠ¸
        template = """
        ë„ˆëŠ” ì„œê°•ëŒ€í•™êµ ë¡œìšœë¼ ë„ì„œê´€ ë„ìš°ë¯¸ì•¼.
        ì•„ë˜ ì»¨í…ìŠ¤íŠ¸ì™€ ì´ì „ ëŒ€í™”ë¥¼ ì°¸ê³ í•´ì„œ, í•„ìš”í•œ ì •ë³´ë§Œ ë‹µë³€í•´.
        ë¶ˆí™•ì‹¤í•˜ë©´ "ì œê³µëœ ì •ë³´ë¡œëŠ” ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µí•´.

        ì¶œë ¥ ê·œì¹™:
        1. í•­ìƒ `### ğŸ” ìƒì„¸ ì„¤ëª…` ì„¹ì…˜ ì¶œë ¥ (ì œëª©ì€ ìƒëµ).
        2. ë‹µë³€ì´ ë„ˆë¬´ ê¸¸ë©´ `### âœï¸ í•µì‹¬ ìš”ì•½`ë„ ì¶œë ¥.
        3. í•­ìƒ `### ğŸ”— ê´€ë ¨ ë§í¬` ì„¹ì…˜ ì¶œë ¥ (HTML `<a>` íƒœê·¸).

        ---
        ì´ì „ ëŒ€í™”: {history}

        ì»¨í…ìŠ¤íŠ¸: {context}

        ì§ˆë¬¸: {question}

        ì‘ë‹µ:
        """
        prompt = PromptTemplate.from_template(template)
        chain = prompt | self.model | StrOutputParser()

        response = chain.invoke(
            {"question": user_question, "context": docs, "history": history_text}
        )

        return {
            "answer": response,
            "sources": [d.metadata.get("source", "") for d in docs],
        }
